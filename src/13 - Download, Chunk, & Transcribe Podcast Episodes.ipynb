{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f2e321-3a5a-4ce5-b3be-5eaa55db6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moviepy pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321aab29-3a1f-42d2-967f-01b5588bcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pathlib\n",
    "import json\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "from helpers import utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae52df0f-0413-4abe-bd41-8cdb7efa9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBS_DIR = pathlib.Path().resolve().parent\n",
    "BASE_DIR = NBS_DIR\n",
    "DATASET_DIR = BASE_DIR / \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839ebc0e-c346-4a7c-9289-ea45f569f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = \"tiny\" # tiny, base, small, medium, large \n",
    "model = whisper.load_model(whisper_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54bc9b92-4add-4884-8e72-781fc4d9d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_audio_chunks(auto_path, chunk_dir=None):\n",
    "    path = pathlib.Path(auto_path).resolve()\n",
    "    if f\"{str(path)}\".endswith('.mp4'):\n",
    "        clip = VideoFileClip(str(path))\n",
    "        audio = clip.audio\n",
    "        path = path.parent / 'audio.mp3'\n",
    "        audio.write_audiofile(str(path))\n",
    "    myaudio = AudioSegment.from_file(str(path))\n",
    "    chunks = make_chunks(myaudio, 30 * 1000) # 30 seconds -> 30_000 ms\n",
    "    #Export all of the individual chunks as wav files\n",
    "    parent = path.parent\n",
    "    if not isinstance(chunk_dir, pathlib.Path): \n",
    "        chunk_dir = parent / \"chunk\"\n",
    "    chunk_dir.mkdir(exist_ok=True)\n",
    "    for current_chunk_path in chunk_dir.glob(\"*.wav\"):\n",
    "        current_chunk_path.unlink()\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        i_padded = f\"{i}\"\n",
    "        if len(i_padded) == 1:\n",
    "            i_padded = f\"0{i}\"\n",
    "        chunk_name = chunk_dir / f\"{i_padded}-chunk.wav\"\n",
    "        chunk.export(str(chunk_name), format=\"wav\")\n",
    "    return len(list(chunk_dir.glob('*.wav')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43dfe21c-4de4-42b2-b3a6-a6c573cd22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(chunk_path):\n",
    "    audio = whisper.load_audio(str(chunk_path))\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    if whisper_model == \"large\":\n",
    "        mel = whisper.log_mel_spectrogram(audio=audio, n_mels=128).to(model.device)\n",
    "    else:\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    # detect the spoken language\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    return max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f37105f-71b5-47b0-8725-39163dada923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking audio.mp3\n",
      "Chunking done with 105 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 16-chunk.wav\n",
      "Detected language: pt\n",
      "Prediected audio language is pt\n",
      "\n",
      "Chunking audio.mp3\n",
      "Chunking done with 10 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 05-chunk.wav\n",
      "Detected language: it\n",
      "Prediected audio language is it\n",
      "\n",
      "Chunking video.mp4\n",
      "MoviePy - Writing audio in /Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39343831/podcasts/1000526377303/audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Chunking done with 71 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 56-chunk.wav\n",
      "Detected language: en\n",
      "Prediected audio language is en\n",
      "\n",
      "Chunking audio.mp3\n",
      "Chunking done with 116 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 68-chunk.wav\n",
      "Detected language: en\n",
      "Prediected audio language is en\n",
      "\n",
      "Chunking video.mp4\n",
      "Chunking done with 0 total chunks\n",
      "Extracting audio language\n",
      "Prediected audio language is unknown\n",
      "\n",
      "Chunking audio.mp3\n",
      "Chunking done with 47 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 24-chunk.wav\n",
      "Detected language: en\n",
      "Prediected audio language is en\n",
      "\n",
      "Chunking audio.mp3\n",
      "Chunking done with 98 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 30-chunk.wav\n",
      "Detected language: en\n",
      "Prediected audio language is en\n",
      "\n",
      "Chunking audio.mp3\n",
      "Chunking done with 181 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 55-chunk.wav\n",
      "Detected language: en\n",
      "Prediected audio language is en\n",
      "\n",
      "Chunking audio.mp3\n",
      "Chunking done with 101 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 10-chunk.wav\n",
      "Detected language: en\n",
      "Prediected audio language is en\n",
      "\n",
      "Chunking audio.mp3\n",
      "Chunking done with 48 total chunks\n",
      "Extracting audio language\n",
      "Random sample for language detection 36-chunk.wav\n",
      "Detected language: id\n",
      "Prediected audio language is id\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def download_and_chunk_audio_files(max_podcasts=10):\n",
    "    for path in list(DATASET_DIR.glob(\"**/**/podcast.json\"))[:max_podcasts]:\n",
    "        podcast_detail_dir = path.parent\n",
    "        podcasts_dir = podcast_detail_dir.parent\n",
    "        post_dir = podcasts_dir.parent\n",
    "        post_id = post_dir.name\n",
    "        podcast_data = json.loads(path.read_text())\n",
    "        podcast_id = podcast_data.get('trackId')\n",
    "        episode_url = podcast_data.get('episodeUrl')\n",
    "        # print(episode_url, podcast_detail_dir)\n",
    "        episode_url = utils.convert_encoded_url(episode_url)\n",
    "        fname = utils.get_fname(episode_url)\n",
    "        if fname is None:\n",
    "            continue\n",
    "        fpath = podcast_detail_dir / fname\n",
    "        if not fpath.exists():\n",
    "            print(\"Downloading\", fname)\n",
    "            fname = utils.download_file(episode_url, destination_path=podcast_detail_dir)\n",
    "            print('Download complete')\n",
    "        print('Chunking', fname)\n",
    "        chunk_dir = podcast_detail_dir / \"chunk\"\n",
    "        total_chunks = 0\n",
    "        try:\n",
    "            total_chunks = make_audio_chunks(fpath, chunk_dir=chunk_dir)\n",
    "        except:\n",
    "            pass\n",
    "        print('Chunking done with', total_chunks, 'total chunks')\n",
    "        print('Extracting audio language')\n",
    "        lang = \"unknown\"\n",
    "        chunk_list = list(chunk_dir.glob(\"*.wav\"))\n",
    "        if len(chunk_list)>0:\n",
    "            random_chunk = random.choice(chunk_list)\n",
    "            print('Random sample for language detection', pathlib.Path(random_chunk).name)\n",
    "            try:\n",
    "                lang = detect_language(random_chunk)\n",
    "            except:\n",
    "                pass\n",
    "            lang_path = podcast_detail_dir / \"pred-language.txt\"\n",
    "        lang_path.write_text(lang)\n",
    "        print('Prediected audio language is', lang)\n",
    "        print()\n",
    "\n",
    "download_and_chunk_audio_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2835f00-3af4-480d-9033-f3f3f110407b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8ad5f05-8a0b-4486-beae-73a0f1910a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing 1000580771305\n",
      "Working on chunk/00-chunk.wav\n",
      "Working on chunk/01-chunk.wav\n",
      "Working on chunk/02-chunk.wav\n",
      "Working on chunk/03-chunk.wav\n",
      "Working on chunk/04-chunk.wav\n",
      "Working on chunk/05-chunk.wav\n",
      "Working on chunk/06-chunk.wav\n",
      "Working on chunk/07-chunk.wav\n",
      "Working on chunk/08-chunk.wav\n",
      "Working on chunk/09-chunk.wav\n",
      "\n",
      "Transcribing 1000607733649\n",
      "\n",
      "Transcribing 1000536467166\n",
      "Working on chunk/00-chunk.wav\n",
      "Working on chunk/01-chunk.wav\n",
      "Working on chunk/02-chunk.wav\n",
      "Working on chunk/03-chunk.wav\n",
      "Working on chunk/04-chunk.wav\n",
      "Working on chunk/05-chunk.wav\n",
      "Working on chunk/06-chunk.wav\n",
      "Working on chunk/07-chunk.wav\n",
      "Working on chunk/08-chunk.wav\n",
      "Working on chunk/09-chunk.wav\n",
      "Working on chunk/10-chunk.wav\n",
      "Working on chunk/11-chunk.wav\n",
      "Working on chunk/12-chunk.wav\n",
      "Working on chunk/13-chunk.wav\n",
      "Working on chunk/14-chunk.wav\n",
      "Working on chunk/15-chunk.wav\n",
      "Working on chunk/16-chunk.wav\n",
      "Working on chunk/17-chunk.wav\n",
      "Working on chunk/18-chunk.wav\n",
      "Working on chunk/19-chunk.wav\n",
      "Working on chunk/20-chunk.wav\n",
      "Working on chunk/21-chunk.wav\n",
      "Working on chunk/22-chunk.wav\n",
      "Working on chunk/23-chunk.wav\n",
      "Working on chunk/24-chunk.wav\n",
      "Working on chunk/25-chunk.wav\n",
      "Working on chunk/26-chunk.wav\n",
      "Working on chunk/27-chunk.wav\n",
      "Working on chunk/28-chunk.wav\n",
      "Working on chunk/29-chunk.wav\n",
      "Working on chunk/30-chunk.wav\n",
      "Working on chunk/31-chunk.wav\n",
      "Working on chunk/32-chunk.wav\n",
      "Working on chunk/33-chunk.wav\n",
      "Working on chunk/34-chunk.wav\n",
      "Working on chunk/35-chunk.wav\n",
      "Working on chunk/36-chunk.wav\n",
      "Working on chunk/37-chunk.wav\n",
      "Working on chunk/38-chunk.wav\n",
      "Working on chunk/39-chunk.wav\n",
      "Working on chunk/40-chunk.wav\n",
      "Working on chunk/41-chunk.wav\n",
      "Working on chunk/42-chunk.wav\n",
      "Working on chunk/43-chunk.wav\n",
      "Working on chunk/44-chunk.wav\n",
      "Working on chunk/45-chunk.wav\n",
      "Working on chunk/46-chunk.wav\n",
      "Working on chunk/47-chunk.wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def transcribe_chunks(transcribe_all = True, max_podcasts=10):\n",
    "    for path in list(DATASET_DIR.glob(\"**/**/podcast.json\"))[:max_podcasts]:\n",
    "        podcast_detail_dir = path.parent\n",
    "        lang_path = podcast_detail_dir / \"pred-language.txt\"\n",
    "        if not lang_path.exists():\n",
    "            continue\n",
    "        transcript_path = podcast_detail_dir / 'transcript.txt'\n",
    "        if transcript_path.exists() and not transcribe_all:\n",
    "            continue\n",
    "        chunk_dir = podcast_detail_dir / \"chunk\"\n",
    "        files = list(chunk_dir.glob(\"*.wav\"))\n",
    "        sorted_files = sorted(files, key=lambda file: int(file.stem.split('-')[0]))\n",
    "        print('Transcribing', podcast_detail_dir.name)\n",
    "        for chunk_path in sorted_files:\n",
    "            chunk_path = pathlib.Path(chunk_path).resolve()\n",
    "            print('Working on', chunk_path.relative_to(podcast_detail_dir))\n",
    "            result = model.transcribe(str(chunk_path)) \n",
    "            chunk_text_path = chunk_path.parent / f\"{chunk_path.stem}.json\"\n",
    "            chunk_text_path.write_text(json.dumps(result))\n",
    "        print()\n",
    "\n",
    "transcribe_chunks(transcribe_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37676a6a-72c0-47c2-81a7-09549e5cb264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39343831/podcasts/1000433799692/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39343831/podcasts/1000580771305/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39343831/podcasts/1000526377303/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39343831/podcasts/1000469341474/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39343831/podcasts/1000607733649/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39343831/podcasts/1000623600545/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39343831/podcasts/1000614308081/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39344643/podcasts/1000575413261/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39344643/podcasts/1000456176903/transcript.txt done\n",
      "/Users/cfe/Dev/smarter-scraping/dataset/2024-02-13/posts/39344643/podcasts/1000536467166/transcript.txt done\n"
     ]
    }
   ],
   "source": [
    "def chunk_transcriptions_to_full_transcript():\n",
    "    for path in list(DATASET_DIR.glob(\"**/**/podcast.json\")):\n",
    "        podcast_detail_dir = path.parent\n",
    "        lang_path = podcast_detail_dir / \"pred-language.txt\"\n",
    "        if not lang_path.exists():\n",
    "            continue\n",
    "        chunk_dir = podcast_detail_dir / \"chunk\"\n",
    "        transcript = \"\"\n",
    "        files = list(chunk_dir.glob(\"*.json\"))\n",
    "        sorted_files = sorted(files, key=lambda file: int(file.stem.split('-')[0]))\n",
    "        for result_path in sorted_files:\n",
    "            result_path = pathlib.Path(result_path).resolve()\n",
    "            if not result_path.exists():\n",
    "                continue\n",
    "            try:\n",
    "                result_data = json.loads(result_path.read_text())\n",
    "            except:\n",
    "                result_data = {}\n",
    "            text = result_data.get('text')\n",
    "            if isinstance(text, str):\n",
    "                transcript += f\" {text} \"\n",
    "        transcript_path = podcast_detail_dir / 'transcript.txt'\n",
    "        if transcript != \"\":\n",
    "            transcript_path.write_text(transcript)\n",
    "        print(transcript_path, 'done')\n",
    "\n",
    "chunk_transcriptions_to_full_transcript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43218e0e-a5d3-421b-a4bb-cedb871ff3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee552390-84cb-4b4c-8048-9278c886e785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9faf7-c881-4baa-b4f6-fdd916dadd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1a62b-3e2f-49fd-b18a-377bc1e0ea80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
